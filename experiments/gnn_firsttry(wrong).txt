"""
VERSION 1.0
SCN augmented PDE solver
Keeps the original MP‑PDE encoder(MLP) → processor(GNN/Simplicial) → decoder(CNN) design.
Replaces the GNN kernel with an SCN kernel that handles 0 to 3 simplices.
Uses swish everywhere to match the MP‑PDE style.
Adds small utilities to synthesise datasets for the six benchmark tasks
  (E1/E2/E3 : Burgers / Allen–Cahn / KdV ; WE1/WE2/WE3 : 1‑D Wave variants).
  
source repo: https://github.com/MP-Neural-PDE-Solvers
"""

import math
import torch
import torch.nn as nn
import torch.nn.functional as F
from torch_geometric.nn.conv import MessagePassing
from torch_scatter import scatter_add

# Activation (Swish β‑version used in original MP‑PDE)
class Swish(nn.Module):
    def __init__(self, beta: float = 1.0):
        super().__init__()
        self.beta = beta
    def forward(self, x):
        return x * torch.sigmoid(self.beta * x)

# Basic simplicial convolution (k‑simplex → (k‑1)‑simplex)
class SimplicialConv(MessagePassing):
    def __init__(self, in_channels, out_channels, boundary_index, aggr: str = 'mean'):
        super().__init__(aggr=aggr, node_dim=-2)
        self.boundary_index = boundary_index       # 2×E incidence
        self.lin = nn.Linear(in_channels, out_channels, bias=False)
    def forward(self, x):                          # x: [num_simplices, C]
        return self.propagate(self.boundary_index, x=x)
    def message(self, x_j):                        # lift then linear proj → target faces
        return self.lin(x_j)

# SCN kernel implementing Eq.(10)+(12) + 3‑simplex extension
class SCNKernel(nn.Module):
    def __init__(self, hidden_dim: int, inc_maps: dict, Z_maps: dict, alpha: float = .5):
        super().__init__()
        # Incidence (already normalised Â)
        self.A01: torch.Tensor = inc_maps['0_1']   # edges → nodes
        self.A02: torch.Tensor = inc_maps['0_2']   # triangles → nodes
        self.A12: torch.Tensor = inc_maps['1_2']   # triangles → edges
        self.A23: torch.Tensor = inc_maps['2_3']   # tets      → triangles
        # Z^{‑1/2} diag (stored as vectors for Hadamard)
        self.Z10 = Z_maps['1_0']                   # len = |edges|
        self.Z20 = Z_maps['2_0']                   # len = |triangles|
        self.Z32 = Z_maps['3_2']                   # len = |tets|
        # inner projections (linear in hidden space)
        self.Q0 = nn.Linear(hidden_dim, hidden_dim, bias=False)
        self.Q1 = nn.Linear(hidden_dim, hidden_dim, bias=False)
        self.Q2 = nn.Linear(hidden_dim, hidden_dim, bias=False)
        self.Q3 = nn.Linear(hidden_dim, hidden_dim, bias=False)
        self.alpha = alpha
        self.act   = Swish()

    def forward(self, X0h, X1h, X2h, X3h):
        """inputs already encoded to hidden_dim"""
        # Direct parts (0‑ and 2‑simplex self‑kernels)
        K0 = self.A01 @ (X0h @ self.Q0.weight.T) @ self.A01.t()
        K2d= self.A02 @ (X0h @ self.Q0.weight.T) @ self.A02.t()
        
        # Indirect: edges → nodes
        K1 = self.A01 @ (self.Z10.unsqueeze(1) * (X1h @ self.Q1.weight.T))
        # Indirect: triangles → nodes (one hop)
        K2i= self.A02 @ (self.Z20.unsqueeze(1) * (X2h @ self.Q2.weight.T))
        # Indirect: tets → triangles → nodes (two hops)
        T2 = self.A23 @ (self.Z32.unsqueeze(1) * (X3h @ self.Q3.weight.T))
        K3 = self.A02 @ (self.Z20.unsqueeze(1) * T2)
        H  = self.alpha * (K0 + K2d) + (1.0 - self.alpha) * (K1 + K2i + K3)
        return self.act(H)                        

# SCN‑PDE model (encoder → kernel → decoder)
class SCNPDEModel(nn.Module):
    def __init__(self, mesh, time_steps: int, feat_dims: dict, hidden: int = 128, alpha: float = .5):
        super().__init__()
        inc, Z = build_scn_maps(mesh, time_steps)
        # Encoders (raw → hidden) for each simplex order
        self.enc0 = nn.Sequential(nn.Linear(feat_dims['node'], hidden), Swish())
        self.enc1 = nn.Sequential(nn.Linear(feat_dims['edge'], hidden), Swish())
        self.enc2 = nn.Sequential(nn.Linear(feat_dims['triangle'], hidden), Swish())
        self.enc3 = nn.Sequential(nn.Linear(feat_dims['tetra'], hidden), Swish())
        # Kernel + decoder
        self.kernel  = SCNKernel(hidden, inc, Z, alpha)
        self.decoder = nn.Sequential(nn.Conv1d(hidden, feat_dims['node'], kernel_size=1), Swish())

    def forward(self, X0, X1, X2, X3):
        X0h = self.enc0(X0)
        H   = self.kernel(X0h, self.enc1(X1), self.enc2(X2), self.enc3(X3))
        return self.decoder(H.unsqueeze(-1)).squeeze(-1)

# Helper functions for topology construction
def normalize_incidence(index: torch.Tensor):
    """Return sparse Z^{‑1/2} A Z^{‑1/2}. *index* is 2×E long tensor."""
    r, c = index
    n_r = int(r.max()) + 1
    n_c = int(c.max()) + 1
    v   = torch.ones_like(r, dtype=torch.float32)
    A   = torch.sparse_coo_tensor(index, v, (n_r, n_c))
    d_r = torch.sparse.sum(A, dim=1).to_dense().add_(1e-8).pow_(-0.5)
    d_c = torch.sparse.sum(A, dim=0).to_dense().add_(1e-8).pow_(-0.5)
    vals = d_r[r] * v * d_c[c]
    return torch.sparse_coo_tensor(index, vals, (n_r, n_c)).coalesce()

def compute_Zinv_vec(index: torch.Tensor, dim: int):
    """Return diag vector of Z^{‑1/2}."""
    rows = index[0]
    deg  = torch.bincount(rows, minlength=dim).float() + 1e-8
    return deg.pow(-0.5)

def extrude_triangles_to_tets(tri: torch.Tensor, T: int):
    num_nodes = int(tri.max()) + 1
    tets = []
    for t in range(T - 1):
        o, n = t * num_nodes, (t + 1) * num_nodes
        for a, b, c in tri.tolist():
            tets.append([a + o, b + o, c + o, a + n])
    return torch.tensor(tets, dtype=torch.long).t() if tets else torch.empty(4, 0, dtype=torch.long)

def build_scn_maps(mesh, T: int):
    # Spatial incidences
    A01 = normalize_incidence(mesh.edge_index)
    A02 = normalize_incidence(mesh.tri_to_node_index)
    A12 = normalize_incidence(mesh.tri_to_edge_index)
    # Space–time extrusion
    A23 = normalize_incidence(extrude_triangles_to_tets(mesh.triangles, T))
    Z10 = compute_Zinv_vec(mesh.edge_index,         mesh.num_nodes)
    Z20 = compute_Zinv_vec(mesh.tri_to_node_index,  mesh.num_nodes)
    Z32 = compute_Zinv_vec(A23.indices(),           A23.size(0))
    return ({'0_1': A01, '0_2': A02, '1_2': A12, '2_3': A23},
            {'1_0': Z10, '2_0': Z20, '3_2': Z32})

# Minimal dataset generator for benchmark tasks E1/E2/E3 & WE1/WE2/WE3
def generate_task_dataset(task: str, n_points: int = 512, T: int = 11):
    """Return (mesh, u_init, eq_params) for a toy 1‑D PDE benchmark.
    *task*: one of E1,E2,E3 (diff‑dom) or WE1‑WE3 (wave).
    """
    x = torch.linspace(0, 1, n_points)
    # build 1‑D chain mesh
    edge_index = torch.stack([torch.arange(n_points - 1), torch.arange(1, n_points)])
    mesh = type('Mesh', (), {})()  # simple anonymous object
    mesh.num_nodes = n_points
    mesh.edge_index = edge_index
                                                            # dummy triangles/tets for 1‑D: create empty placeholders
    mesh.triangles = torch.empty(0, 3, dtype=torch.long)
    mesh.tri_to_node_index = torch.empty(2, 0, dtype=torch.long)
    mesh.tri_to_edge_index = torch.empty(2, 0, dtype=torch.long)
                                                            # PDE specific parameters (normalized later)
    params = {}
    if task == 'E1':# e.g. Burgers (α)
        params['alpha'] = torch.tensor(0.1)
    elif task == 'E2':# Allen–Cahn (β)
        params['beta'] = torch.tensor(0.01)
    elif task == 'E3':# KdV (γ)
        params['gamma'] = torch.tensor(6.0)
    elif task.startswith('WE'):
        params['c'] = torch.tensor(float(task[-1]))  # wave speed 1,2,3
    # initial state u(x,0)
    u0 = torch.sin(2 * math.pi * x).unsqueeze(1)     # [N,1]
    return mesh, u0, params





